{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be learning regular expressions while performing analysis on a dataset of submissions to popular technology site Hacker News.\n",
    "<br>\n",
    "<br>\n",
    "The dataset we will be working with is based off this CSV of Hacker News stories from September 2015 to September 2016. The columns in the dataset are explained below:\n",
    "- id: The unique identifier from Hacker News for the story\n",
    "- title: The title of the story\n",
    "- url: The URL that the stories links to, if the story has a URL\n",
    "- num_points: The number of points the story acquired, calculated as the total number of upvotes minus the total number of \n",
    "  downvotes\n",
    "- num_comments: The number of comments that were made on the story\n",
    "- author: The username of the person who submitted the story\n",
    "- created_at: The date and time at which the story was submitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First is to import the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>num_points</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12224879</td>\n",
       "      <td>Interactive Dynamic Video</td>\n",
       "      <td>http://www.interactivedynamicvideo.com/</td>\n",
       "      <td>386</td>\n",
       "      <td>52</td>\n",
       "      <td>ne0phyte</td>\n",
       "      <td>8/4/2016 11:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11964716</td>\n",
       "      <td>Florida DJs May Face Felony for April Fools' W...</td>\n",
       "      <td>http://www.thewire.com/entertainment/2013/04/f...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>vezycash</td>\n",
       "      <td>6/23/2016 22:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11919867</td>\n",
       "      <td>Technology ventures: From Idea to Enterprise</td>\n",
       "      <td>https://www.amazon.com/Technology-Ventures-Ent...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>hswarna</td>\n",
       "      <td>6/17/2016 0:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10301696</td>\n",
       "      <td>Note by Note: The Making of Steinway L1037 (2007)</td>\n",
       "      <td>http://www.nytimes.com/2007/11/07/movies/07ste...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>walterbell</td>\n",
       "      <td>9/30/2015 4:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10482257</td>\n",
       "      <td>Title II kills investment? Comcast and other I...</td>\n",
       "      <td>http://arstechnica.com/business/2015/10/comcas...</td>\n",
       "      <td>53</td>\n",
       "      <td>22</td>\n",
       "      <td>Deinos</td>\n",
       "      <td>10/31/2015 9:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>10557283</td>\n",
       "      <td>Nuts and Bolts Business Advice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>shomberj</td>\n",
       "      <td>11/13/2015 0:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>12296411</td>\n",
       "      <td>Ask HN: How to improve my personal website?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>ahmedbaracat</td>\n",
       "      <td>8/16/2016 9:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>11337617</td>\n",
       "      <td>Shims, Jigs and Other Woodworking Concepts to ...</td>\n",
       "      <td>http://firstround.com/review/shims-jigs-and-ot...</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>zt</td>\n",
       "      <td>3/22/2016 16:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10379326</td>\n",
       "      <td>That self-appendectomy</td>\n",
       "      <td>http://www.southpolestation.com/trivia/igy1/ap...</td>\n",
       "      <td>91</td>\n",
       "      <td>10</td>\n",
       "      <td>jimsojim</td>\n",
       "      <td>10/13/2015 9:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>11370829</td>\n",
       "      <td>Crate raises $4M seed round for its next-gen S...</td>\n",
       "      <td>http://techcrunch.com/2016/03/15/crate-raises-...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>hitekker</td>\n",
       "      <td>3/27/2016 18:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  12224879                          Interactive Dynamic Video   \n",
       "1  11964716  Florida DJs May Face Felony for April Fools' W...   \n",
       "2  11919867       Technology ventures: From Idea to Enterprise   \n",
       "3  10301696  Note by Note: The Making of Steinway L1037 (2007)   \n",
       "4  10482257  Title II kills investment? Comcast and other I...   \n",
       "5  10557283                     Nuts and Bolts Business Advice   \n",
       "6  12296411        Ask HN: How to improve my personal website?   \n",
       "7  11337617  Shims, Jigs and Other Woodworking Concepts to ...   \n",
       "8  10379326                             That self-appendectomy   \n",
       "9  11370829  Crate raises $4M seed round for its next-gen S...   \n",
       "\n",
       "                                                 url  num_points  \\\n",
       "0            http://www.interactivedynamicvideo.com/         386   \n",
       "1  http://www.thewire.com/entertainment/2013/04/f...           2   \n",
       "2  https://www.amazon.com/Technology-Ventures-Ent...           3   \n",
       "3  http://www.nytimes.com/2007/11/07/movies/07ste...           8   \n",
       "4  http://arstechnica.com/business/2015/10/comcas...          53   \n",
       "5                                                NaN           3   \n",
       "6                                                NaN           2   \n",
       "7  http://firstround.com/review/shims-jigs-and-ot...          34   \n",
       "8  http://www.southpolestation.com/trivia/igy1/ap...          91   \n",
       "9  http://techcrunch.com/2016/03/15/crate-raises-...           3   \n",
       "\n",
       "   num_comments        author       created_at  \n",
       "0            52      ne0phyte   8/4/2016 11:52  \n",
       "1             1      vezycash  6/23/2016 22:20  \n",
       "2             1       hswarna   6/17/2016 0:01  \n",
       "3             2    walterbell   9/30/2015 4:12  \n",
       "4            22        Deinos  10/31/2015 9:48  \n",
       "5             4      shomberj  11/13/2015 0:45  \n",
       "6             6  ahmedbaracat   8/16/2016 9:55  \n",
       "7             7            zt  3/22/2016 16:18  \n",
       "8            10      jimsojim  10/13/2015 9:30  \n",
       "9             1      hitekker  3/27/2016 18:08  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "hn = pd.read_csv('hacker_news.csv')\n",
    "hn.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The regular Expression Module "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with regular expressions, we use the term pattern to describe a regular expression that we've written. If the pattern is found within the string we're searching, we say that it has matched.\n",
    "<br>\n",
    "<br>\n",
    "We previously used regular expressions with pandas, but Python also has a built-in module for regular expressions: The re module. This module contains a number of different functions and classes for working with regular expressions. \n",
    "<br>\n",
    "<br>\n",
    "One of the most useful functions from the re module is the re.search() function, which takes two required arguments:\n",
    "- The regex pattern\n",
    "- The string we want to search that pattern for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(1, 4), match='and'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "m = re.search(\"and\", \"hand\")\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The re.search() function will return a Match object if the pattern is found anywhere within the string. If the pattern is not found, re.search() returns None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "m = re.search(\"and\", \"antidote\")\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we can use the fact that the boolean value of a match object is True while None is False to easily check whether our regex matches each string in a list. We'll create a list of three simple strings to use while learning these concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match\n",
      "No Match\n",
      "No Match\n"
     ]
    }
   ],
   "source": [
    "string_list = [\"Julie's favorite color is Blue.\",\n",
    "               \"Keli's favorite color is Green.\",\n",
    "               \"Craig's favorite colors are blue and red.\"]\n",
    "\n",
    "pattern = \"Blue\"\n",
    "\n",
    "for s in string_list:\n",
    "    if re.search(pattern, s):\n",
    "        print(\"Match\")\n",
    "    else:\n",
    "        print(\"No Match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first of these we'll learn is called a set. A set allows us to specify two or more characters that can match in a single character's position.\n",
    "<br>\n",
    "<br>\n",
    "Example: Python/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "titles = hn[\"title\"].tolist()\n",
    "\n",
    "pattern = \"[Pp]ython\"\n",
    "python_mentions = 0 \n",
    "\n",
    "for ele in titles:\n",
    "    if re.search(pattern, ele):\n",
    "        python_mentions += 1 \n",
    "\n",
    "print(python_mentions)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Matches with pandas Methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another alternative to perform the same function but avoid using loops in pandas is the vectorized method. We learned that the **Series.str.contains() method** in pandas can be used to test whether a Series of strings match a particular regex pattern.\n",
    "<br>\n",
    "<br>\n",
    "We'll start by creating a pandas object containing our strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             Julie's favorite color is green.\n",
      "1               Keli's favorite color is Blue.\n",
      "2    Craig's favorite colors are blue and red.\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "eg_list = [\"Julie's favorite color is green.\",\n",
    "           \"Keli's favorite color is Blue.\",\n",
    "           \"Craig's favorite colors are blue and red.\"]\n",
    "\n",
    "eg_series = pd.Series(eg_list)\n",
    "print(eg_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create our regex pattern, and use Series.str.contains() to compare to each value in our series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "pattern = \"[Bb]lue\"\n",
    "\n",
    "pattern_contained = eg_series.str.contains(pattern)\n",
    "print(pattern_contained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the neat things about boolean masks is that you can use the Series.sum() method to sum all the values in the boolean mask, with each True value counting as 1, and each False as 0. This means that we can easily count the number of values in the original series that matched our pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "pattern_count = pattern_contained.sum()\n",
    "print(pattern_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply this concept also in the hacker news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "pattern = '[Pp]ython'\n",
    "\n",
    "titles = hn['title']\n",
    "python_mentions = titles.str.contains(pattern).sum()\n",
    "print(python_mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the previous two screens, we used regular expressions to count how many titles contain Python or python. What if we wanted to view those titles?\n",
    "<br>\n",
    "<br>\n",
    "In that case, we can use the boolean array returned by Series.str.contains() to select just those rows from our series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102                  From Python to Lua: Why We Switched\n",
      "103            Ubuntu 16.04 LTS to Ship Without Python 2\n",
      "144    Create a GUI Application Using Qt and Python i...\n",
      "196    How I Solved GCHQ's Xmas Card with Python and ...\n",
      "436    Unikernel Power Comes to Java, Node.js, Go, an...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "titles = hn['title']\n",
    "\n",
    "py_titles_bool = titles.str.contains(\"[Pp]ython\")\n",
    "py_titles = titles[py_titles_bool]\n",
    "print(py_titles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply the same case in another example e.g select all titles that mention the programming language Ruby, using a set to account for whether the word is capitalized or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190                    Ruby on Google AppEngine Goes Beta\n",
      "484          Related: Pure Ruby Relational Algebra Engine\n",
      "1388    Show HN: HTTPalooza  Ruby's greatest HTTP clie...\n",
      "1949    Rewriting a Ruby C Extension in Rust: How a Na...\n",
      "2022    Show HN: CrashBreak  Reproduce exceptions as f...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "titles = hn['title']\n",
    "\n",
    "ruby_titles = titles[titles.str.contains(\"[Rr]uby\")]\n",
    "print(ruby_titles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifiers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use braces ({}) to specify that a character repeats in our regular expression. For instance, if we wanted to write a pattern that matches the numbers in text from 1000 to 2999 we could write the regular expression below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-16455b5a747c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-16455b5a747c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    [1-2][0-9]{3}\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[1-2][0-9]{3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name for this type of regular expression syntax is called a quantifier. Quantifiers specify how many of the previous character our pattern requires, which can help us when we want to match substrings of specific lengths.\n",
    "<br>\n",
    "<br>\n",
    "As an example, we might want to match both e-mail and email. To do this, we would want to specify to match - either zero or one times.\n",
    "<br>\n",
    "<br>\n",
    "To find how many titles in our dataset mention email or e-mail. To do this, we'll need to use ?, the optional quantifier, to specify that the dash character - is optional in our regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119     Show HN: Send an email from your shell to your...\n",
      "313         Disposable emails for safe spam free shopping\n",
      "1361    Ask HN: Doing cold emails? helps us prove this...\n",
      "1750    Protect yourself from spam, bots and phishing ...\n",
      "2421                   Ashley Madison hack treating email\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "email_bool = titles.str.contains(\"e-?mail\")\n",
    "email_count = email_bool.sum()\n",
    "email_titles = titles[email_bool]\n",
    "print(email_titles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Classes/Accessing Matching Text with Capture Groups "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some stories submitted to Hacker News include a topic tag in brackets, like [pdf]. Here are a few examples of story titles with these tags:\n",
    "- [video] Google Self-Driving SUV Sideswipes Bus\n",
    "- New Directions in Cryptography by Diffie and Hellman (1976) [pdf]\n",
    "- Wallace and Gromit  The Great Train Chase (1993) [video]\n",
    "<br>\n",
    "<br>\n",
    "Our first inclination may be to create the regex [pdf]. Unfortunately, the brackets would be interpreted as a set, so our pattern would match the single characters p, d, or f.\n",
    "<br>\n",
    "<br>\n",
    "To match the substring \"[pdf]\", we can use backslashes to escape both the open and closing brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-18-36834e20a8fa>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-36834e20a8fa>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    \\[pdf\\]\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "\\[pdf\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, there are some other common character classes which we'll use a lot\n",
    "- \\d -- Any digit character\n",
    "- \\w -- Any digit, uppercase, lowercase, or underscore char\n",
    "- \\s -- Any space, tbal or linebreak character\n",
    "- . -- any character except newline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to match word characters between our brackets, we can combine the word character class (\\w) with the 'one or more' quantifier (+), giving us a combined pattern of \\w+.\n",
    "<br>\n",
    "<br>\n",
    "This will match sequences like pdf, video, Python, and 2018 but won't match a sequence containing a space or punctuation character like PHP-DEV or XKCD Flowchart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use these concepts to count the number of titles that contain a tag, which:\n",
    "- A single open bracket character.\n",
    "- One or more word characters.\n",
    "- A single close bracket character.\n",
    "<br>\n",
    "<br>\n",
    "Then select those titles and count how many matching titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = \"\\[\\w+\\]\"\n",
    "tag_titles = titles[titles.str.contains(pattern)]\n",
    "tag_count = tag_titles.shape[0]\n",
    "tag_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A backslash followed by certain characters represents an escape sequence — like the \\n sequence — which we previously learned represents a new line. These escape sequences can result in unintended consequences for our regular expressions. Let's take a look at a string containing the substring \\b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\b world\n"
     ]
    }
   ],
   "source": [
    "print('hello\\b world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The escape sequence \\b represents a backspace, so the final letter from our string is removed. The character sequence \\b has a special meaning in regular expressions (which we'll learn about later), so we need a way to write these characters without triggering the escape sequence.\n",
    "\n",
    "One way is to add an extra backslash before the \"b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\\b world\n"
     ]
    }
   ],
   "source": [
    "print('hello\\\\b world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\\b world\n"
     ]
    }
   ],
   "source": [
    "print(r'hello\\b world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous screen, we were able to calculate that 444 of the 20,100 Hacker News stories in our dataset contain tags. What if we wanted to find out what the text of these tags were, and how many of each are in the dataset?\n",
    "<br>\n",
    "<br>\n",
    "In order to do this, we'll need to use capture groups. Capture groups allow us to specify one or more groups within our match that we can access separately. In this mission, we'll learn how to use one capture group per regular expression, but in the next mission we'll learn some more complex capture group patterns.\n",
    "<br>\n",
    "<br>\n",
    "We use the Series.str.extract() method to extract the match within our parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0\n",
      "66      [pdf]\n",
      "100  [German]\n",
      "159     [pdf]\n",
      "162     [pdf]\n",
      "195    [Beta]\n"
     ]
    }
   ],
   "source": [
    "tag_5 = tag_titles.head()\n",
    "pattern = r\"(\\[\\w+\\])\"\n",
    "tag_5_matches = tag_5.str.extract(pattern)\n",
    "print(tag_5_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can move our parentheses inside the brackets to get just the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "66      pdf\n",
      "100  German\n",
      "159     pdf\n",
      "162     pdf\n",
      "195    Beta\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"\\[(\\w+)\\]\"\n",
    "tag_5_matches = tag_5.str.extract(pattern)\n",
    "print(tag_5_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this technique to extract all of the tags from the Hacker News titles and build a frequency table of those tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0  NaN\n",
      "1  NaN\n",
      "2  NaN\n",
      "3  NaN\n",
      "4  NaN\n"
     ]
    }
   ],
   "source": [
    "# pattern = r\"\\[\\w+\\]\"\n",
    "pattern = r\"\\[(\\w+)\\]\"\n",
    "tag_freq = titles.str.extract(pattern)\n",
    "print(tag_freq.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Character Classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating complex regular expressions, you often need to work iteratively so you can find \"bad\" instances that match your pattern and then exclude them.\n",
    "<br>\n",
    "<br>\n",
    "In order to work faster as you build your regular expression, it can be helpful to create a function that returns the first few matching strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier, we counted the titles that included Python — let's write a simple regular expression to match Java (another popular language), and use our function to look at the matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_10_matches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-6ea913798a63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfirst_10_matches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"[Jj]ava\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'first_10_matches' is not defined"
     ]
    }
   ],
   "source": [
    "first_10_matches(r\"[Jj]ava\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are a number of matches that contain Java as part of the word JavaScript. We want to exclude these titles from matching so we get an accurate count.\n",
    "<br>\n",
    "<br>\n",
    "One way to do this is by using negative character classes. Negative character classes are character classes that match every character except a character class. Let's look at a table of the common negative character classes:\n",
    "- Negative Set -- [^fud] -- Any character except f,u,d\n",
    "- Negative Set -- [^1-3Z\\s] -- Any character except 1,2,3,Z, or whitespace characters\n",
    "- Negative Digit -- \\D -- Any character except digit character\n",
    "- Negative word -- \\W -- Any character except word character\n",
    "- Negative whitespace -- \\W -- Any character except whitespace character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the negative set [^Ss] to exclude instances like JavaScript and Javascript:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436     Unikernel Power Comes to Java, Node.js, Go, an...\n",
      "811     Ask HN: Are there any projects or compilers wh...\n",
      "1840                    Adopting RxJava on the Airbnb App\n",
      "1972          Node.js vs. Java: Which Is Faster for APIs?\n",
      "2093                    Java EE and Microservices in 2016\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def first_10_matches(pattern):\n",
    "    \n",
    "    \n",
    "    all_matches = titles[titles.str.contains(pattern)]\n",
    "    first_10 = all_matches.head(10)\n",
    "    return first_10\n",
    "\n",
    "pattern = r\"[Jj]ava[^Ss]\"\n",
    "java_titles = titles[titles.str.contains(pattern)]\n",
    "print(java_titles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Boundaries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different approach to take in cases like these is to use the word boundary anchor, specified using the syntax \\b. A word boundary matches the position between a word character and a non-word character, or a word character and the start/end of a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436     Unikernel Power Comes to Java, Node.js, Go, an...\n",
      "811     Ask HN: Are there any projects or compilers wh...\n",
      "1023                         Pippo  Web framework in Java\n",
      "1972          Node.js vs. Java: Which Is Faster for APIs?\n",
      "2093                    Java EE and Microservices in 2016\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"\\b[Jj]ava\\b\"\n",
    "java_titles = titles[titles.str.contains(pattern)]\n",
    "print(java_titles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the previous screen, we learned that the word boundary anchor matches the space between a word character and a non-word character. More generally in regular expressions, an anchor matches something that isn't a character, as opposed to character classes which match specific characters.\n",
    "<br>\n",
    "<br>\n",
    "Other than the word boundary anchor, the other two most common anchors are the beginning anchor and the end anchor, which represent the start and the end of the string, respectfully.\n",
    "- Beginning -- ^abc -- Matches abc only at the start of the string \n",
    "- End -- abc$ -- Matches abc only at the end of string "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a few test cases that all contain the substring Red at different parts of the string, as well as a test function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Red Nose Day is a well-known fundraising event\n",
      "1                          My favorite color is Red\n",
      "2          My Red Car was purchased three years ago\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "test_cases = pd.Series([\n",
    "    \"Red Nose Day is a well-known fundraising event\",\n",
    "    \"My favorite color is Red\",\n",
    "    \"My Red Car was purchased three years ago\"\n",
    "])\n",
    "print(test_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching at the Start and End of Strings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to match the word Red only if it occurs at the start of the string, we add the beginning anchor to the start of our regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cases.str.contains(r\"^Red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to match the word Red only if it occurs at the end of the string, we add the end anchor to the end of our regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cases.str.contains(r\"Red$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the beginning and end anchors to count how many titles have tags at the start versus the end of the story title in our Hacker News dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "417\n"
     ]
    }
   ],
   "source": [
    "pattern_beginning = r\"^\\[\\w+\\]\"\n",
    "beginning_count = titles.str.contains(pattern_beginning).sum()\n",
    "\n",
    "pattern_ending =  r\"\\[\\w+\\]$\"\n",
    "ending_count = titles.str.contains(pattern_ending).sum()\n",
    "\n",
    "print(beginning_count)\n",
    "print(ending_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Flags to Modify Regex Patterns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the titles, there are many different formatting styles used to represent the word \"email.\" e.g email, Email, e Mail, e mail, E-mail etc\n",
    "<br>\n",
    "<br>\n",
    "we can use flags to specify that our regular expression should ignore case\n",
    "<br>\n",
    "<br>\n",
    "Both re.search() and the pandas regular expression methods accept an optional flags argument. This argument accepts one or more flags, which are special variables in the re module that modify the behavior of the regex interpreter.\n",
    "<br>\n",
    "<br>\n",
    "A list of all available flags is in the documentation, but by far the most common and the most useful is the re.IGNORECASE flag, which is also available using the alias re.I for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5abd8dab2cf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m email_tests = pd.Series(['email', 'Email', 'e Mail', 'e mail', 'E-mail',\n\u001b[0m\u001b[0;32m      4\u001b[0m               \u001b[1;34m'e-mail'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'eMail'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'E-Mail'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'EMAIL'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'emails'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Emails'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m               'E-Mails'])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "email_tests = pd.Series(['email', 'Email', 'e Mail', 'e mail', 'E-mail',\n",
    "              'e-mail', 'eMail', 'E-Mail', 'EMAIL', 'emails', 'Emails',\n",
    "              'E-Mails'])\n",
    "\n",
    "pattern = r\"\\be[\\-\\s]?mails?\\b\"\n",
    "email_mentions = titles.str.contains(pattern, flags=re.I).sum()\n",
    "email_mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Regular Expressions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignore case  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ignorecase flag is particularly useful when we have many different capitalizations for a word or phrase. In our dataset, the SQL language has three different capitalizations: SQL, sql, and Sql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "hn = pd.read_csv(\"hacker_news.csv\")\n",
    "titles = hn['title']\n",
    "\n",
    "pattern = r\"SQL\"\n",
    "sql_counts = titles.str.contains(pattern, flags=re.I).sum()\n",
    "sql_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture Groups "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend this analysis by looking at titles that have letters immediately before the \"SQL,\" which is a convention often used to denote different variations or flavors of SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flavor</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>cloudsql</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>memsql</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mysql</td>\n",
       "      <td>12.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nosql</td>\n",
       "      <td>14.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>postgresql</td>\n",
       "      <td>25.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sparksql</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            num_comments\n",
       "flavor                  \n",
       "cloudsql        5.000000\n",
       "memsql         14.000000\n",
       "mysql          12.230769\n",
       "nosql          14.529412\n",
       "postgresql     25.962963\n",
       "sparksql        1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract record with SQL/sql from the dataset\n",
    "hn_sql = hn[hn['title'].str.contains(r\"\\w+SQL\", flags=re.I)].copy()\n",
    "\n",
    "# Clean the value in the flavor column by converting them to lowercase. Assign the values back to the column in hn_sql.\n",
    "hn_sql['flavor'] = hn_sql['title'].str.extract(r\"(\\w+SQL)\", re.I)\n",
    "hn_sql['flavor'] = hn_sql['flavor'].str.lower()\n",
    "\n",
    "# Create a pivot table\n",
    "sql_pivot = hn_sql.pivot_table(index='flavor', values='num_comments', aggfunc='mean')\n",
    "sql_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Capture Groups to Extract Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Hacker News titles that mention Python, it mentioned different versions e.g Python 3.6, Python 2.7 or so. \n",
    "<br>\n",
    "<br>\n",
    "So if we want to extract the version number, it can be as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f5cbcea5c160>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"[Pp]ython ([\\d\\.]+)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpy_versions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpy_versions_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_versions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'value_counts'"
     ]
    }
   ],
   "source": [
    "pattern = r\"[Pp]ython ([\\d\\.]+)\"\n",
    "py_versions = titles.str.extract(pattern)\n",
    "py_versions_freq = dict(py_versions.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've created regular expressions to clean and analyze the number of mentions of the Python, SQL, and Java languages. Next up: counting the mentions of the C language.\n",
    "<br>\n",
    "<br>\n",
    "We can start with a simple regular expression and then iterate as we find and exclude incorrect matches. Let's start with a simple regex that matches the letter \"c\" with word boundary anchors on either side. \n",
    "<br>\n",
    "<br>\n",
    "At the same time, we want to prevent: \n",
    "- Mentions of C++, a distinct language from C\n",
    "- Cases where the letter C is followed by a period, like in the substring C.E.O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365                 The new C standards are worth it\n",
      "444      Moz raises $10m Series C from Foundry Group\n",
      "521     Fuchsia: Micro kernel written in C by Google\n",
      "1307       Show HN: Yupp, yet another C preprocessor\n",
      "1326                The C standard formalized in Coq\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def first_10_matches(pattern):\n",
    "    \"\"\"\n",
    "    Return the first 10 story titles that match\n",
    "    the provided regular expression\n",
    "    \"\"\"\n",
    "    all_matches = titles[titles.str.contains(pattern)]\n",
    "    first_10 = all_matches.head(10)\n",
    "    return first_10\n",
    "\n",
    "first_ten = first_10_matches(r\"\\b[Cc]\\b[^.+]\")\n",
    "print(first_ten.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Lookarounds to control Matches Based on Surrounding Text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we're getting close. In our first 10 matches we have one irrelevant result, which is about \"Series C,\" a term used to represent a particular type of startup fundraising.\n",
    "<br>\n",
    "<br>\n",
    "Additionally, we've run into the same issue as we did in the previous mission — by using a negative set, we may have eliminated any instances where the last character of the title is \"C\" (the second last line of output matches in spite of the fact that it ends with \"C,\" because it also has \"C\" earlier in the string).\n",
    "<br>\n",
    "<br>\n",
    "We need a new tool called lookarounds. Lookarounds let us define a character or sequence of characters that either must or must not come before or after our regex match. There are four types of lookarounds\n",
    "- Positive Lookahead --- zzz(?=abc) --- Matches zzz only when it is followed by abc \n",
    "- Negative Lookahead --- zzz(?!abc) --- Matches zzz only when it is not followed by abc \n",
    "- Positive Lookbehind --- (?<=abc)zzz --- Matches zzz only when it is preceded by abc\n",
    "- Negative Lookbehind --- (?<!abc)zzz --- Matches zzz only when it is not preceded by abc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also create a function that will loop over our test cases and tell us whether our pattern matches. We'll use the re module rather than pandas since it tells us the exact text that matches, which will help us understand how the lookaround is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = ['Red_Green_Blue',\n",
    "              'Yellow_Green_Red',\n",
    "              'Red_Green_Red',\n",
    "              'Yellow_Green_Blue',\n",
    "              'Green']\n",
    "\n",
    "#  Create a function that will loop over our test cases and tell us whether our pattern matches.\n",
    "def run_test_cases(pattern):\n",
    "    for tc in test_cases:\n",
    "        result = re.search(pattern, tc)\n",
    "        print(result or \"NO MATCH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by using a positive lookahead to include instances where the match is followed by the substring _Blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "NO MATCH\n",
      "<re.Match object; span=(7, 12), match='Green'>\n",
      "NO MATCH\n"
     ]
    }
   ],
   "source": [
    "run_test_cases(r\"Green(?=_Blue)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a negative lookahead to include instances where the match is not followed by the substring _Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "NO MATCH\n"
     ]
    }
   ],
   "source": [
    "run_test_cases(r\"(?<=Red_)Green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive lookbehind to include instances where the match is preceded by the substring Red_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "NO MATCH\n"
     ]
    }
   ],
   "source": [
    "run_test_cases(r\"(?<=Red_)Green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative lookbehind to include instances where the match isn't preceded by the substring Yellow_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "<re.Match object; span=(0, 5), match='Green'>\n"
     ]
    }
   ],
   "source": [
    "run_test_cases(r\"(?<!Yellow_)Green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of a lookaround can include any other regular expression component. For instance, here is an example where we match only cases that are followed by exactly five characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "NO MATCH\n",
      "<re.Match object; span=(7, 12), match='Green'>\n",
      "NO MATCH\n"
     ]
    }
   ],
   "source": [
    "run_test_cases(r\"Green(?=.{5})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this pattern to exclude matches that are followed by . or +, but still match cases where \"C\" falls at the end of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r'(?<!Series\\s)\\b[Cc]\\b(?![\\.\\+])'\n",
    "c_mentions = titles.str.contains(pattern).sum()\n",
    "c_mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Capture Groups in a RegEx Pattern "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we wanted to identify strings that had words with double letters, like the \"ee\" in \"feed.\" Because we don't know ahead of time what letters might be repeated, we need a way to specify a capture group and then to repeat it. We can do this with backreferences.\n",
    "<br>\n",
    "<br>\n",
    "For example: In the regex that matches 'HelloGoodbye':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Hello' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-bd10ac078464>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mHello\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGoodbye\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Hello' is not defined"
     ]
    }
   ],
   "source": [
    "(Hello)(Goodbye)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be written into group like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-46-941a68bb0920>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-46-941a68bb0920>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    (Hello)(Goodbye) \\2\\1\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "(Hello)(Goodbye) \\2\\1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression above will match the text HelloGoodbyeGoodbyeHello\n",
    "<br>\n",
    "<br>\n",
    "Let's see this in action using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(21, 23), match='oo'>\n",
      "<re.Match object; span=(2, 4), match='ee'>\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(13, 15), match='ee'>\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "              \"I'm going to read a book.\",\n",
    "              \"Green is my favorite color.\",\n",
    "              \"My name is Aaron.\",\n",
    "              \"No doubles here.\",\n",
    "              \"I have a pet eel.\"\n",
    "             ]\n",
    "\n",
    "for tc in test_cases:\n",
    "    print(re.search(r\"(\\w)\\1\", tc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write a regular expression to match cases of repeated words, and select only the items in titles that match the regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3102                 Silicon Valley Has a Problem Problem\n",
      "3176               Wire Wire: A West African Cyber Threat\n",
      "3178                        Flexbox Cheatsheet Cheatsheet\n",
      "4797                           The Mindset Mindset (2015)\n",
      "7276    Valentine's Day Special: Bye Bye Tinder, Flirt...\n",
      "Name: title, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pakhl\\Anaconda3\\lib\\site-packages\\pandas\\core\\strings.py:1843: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "pattern = r'\\b(\\w+)\\s\\1\\b'\n",
    "repeated_words = titles[titles.str.contains(pattern)]\n",
    "print(repeated_words.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we learned to work with basic string methods, we used the str.replace() method to replace simple substrings. We can achieve the same with regular expressions using the re.sub() function. The basic syntax for re.sub() is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'repl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-b55d133d7a41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'repl' is not defined"
     ]
    }
   ],
   "source": [
    "re.sub(pattern, repl, string, flags=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working in pandas, we can use the Series.str.replace() method, which uses nearly identical syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c6fb01d07325>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSeries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Series' is not defined"
     ]
    }
   ],
   "source": [
    "Series.str.replace(pat, repl, flags=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substituting Regular Expression Matches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided email_variations, a pandas Series containing all the variations of \"email\" in the dataset.\n",
    "<br>\n",
    "<br>\n",
    "We can use a regular expression to replace each of the matches in email_variations with \"email\" and assign the result to email_uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_variations = pd.Series(['email', 'Email', 'e Mail',\n",
    "                        'e mail', 'E-mail', 'e-mail',\n",
    "                        'eMail', 'E-Mail', 'EMAIL'])\n",
    "\n",
    "pattern = r'[Ee][\\s\\-]?mail'\n",
    "email_uniform = email_variations.str.replace(pattern, 'email', flags=re.I)\n",
    "titles_clean = titles.str.replace(pattern, 'email', flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    email\n",
      "1    email\n",
      "2    email\n",
      "3    email\n",
      "4    email\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(email_uniform.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titles_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8a75d052e114>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitles_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'titles_clean' is not defined"
     ]
    }
   ],
   "source": [
    "print(titles_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Domains from URLs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll extract components of URLs from our dataset. As a reminder, most stories on Hacker News contain a link to an external resource.\n",
    "<br>\n",
    "<br>\n",
    "The task we will be performing first is extracting the different components of the URLs in order to analyze them. On this screen, we'll start by extracting just the domains.\n",
    "<br>\n",
    "<br>\n",
    "The domain of each URL excludes the protocol (e.g. https://) and the page path (e.g. /Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429).\n",
    "<br>\n",
    "<br>\n",
    "Write a regular expression to extract the domains from test_urls and assign the result to test_urls_clean. Please note: \n",
    "- Using a series of characters that will match the protocol\n",
    "- Inside a capture group, using a set that will match the character classes used in the domain.\n",
    "- Because all of the URLs either end with the domain, or continue with page path which starts with / (a character not found in \n",
    "  any domains), we don't need to cater for this part of the URL in our regular expression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 0\n",
      "0                   www.amazon.com\n",
      "1  www.interactivedynamicvideo.com\n",
      "2                  www.nytimes.com\n",
      "3                    evonomics.com\n",
      "4                       github.com\n"
     ]
    }
   ],
   "source": [
    "test_urls = pd.Series([\n",
    " 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
    " 'http://www.interactivedynamicvideo.com/',\n",
    " 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
    " 'http://evonomics.com/advertising-cannot-maintain-internet-heres-solution/',\n",
    " 'HTTPS://github.com/keppel/pinn',\n",
    " 'Http://phys.org/news/2015-09-scale-solar-youve.html',\n",
    " 'https://iot.seeed.cc',\n",
    " 'http://www.bfilipek.com/2016/04/custom-deleters-for-c-smart-pointers.html',\n",
    " 'http://beta.crowdfireapp.com/?beta=agnipath',\n",
    " 'https://www.valid.ly?param',\n",
    " 'http://css-cursor.techstream.org'\n",
    "])\n",
    "\n",
    "pattern = r\"https?://([\\w\\-\\.]+)\"\n",
    "\n",
    "test_urls_clean = test_urls.str.extract(pattern, flags=re.I)\n",
    "print(test_urls_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting URL Parts Using Multiple Capture Groups "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the same time we can extract other components with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(https?)://([\\w\\.\\-]+)/?(.*)\"\n",
    "\n",
    "test_url_parts = test_urls.str.extract(pattern, flags=re.I)\n",
    "url_parts = hn['url'].str.extract(pattern, flags=re.I) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>https</td>\n",
       "      <td>www.amazon.com</td>\n",
       "      <td>Technology-Ventures-Enterprise-Thomas-Byers/dp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>http</td>\n",
       "      <td>www.interactivedynamicvideo.com</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>http</td>\n",
       "      <td>www.nytimes.com</td>\n",
       "      <td>2007/11/07/movies/07stein.html?_r=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>http</td>\n",
       "      <td>evonomics.com</td>\n",
       "      <td>advertising-cannot-maintain-internet-heres-sol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HTTPS</td>\n",
       "      <td>github.com</td>\n",
       "      <td>keppel/pinn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                1  \\\n",
       "0  https                   www.amazon.com   \n",
       "1   http  www.interactivedynamicvideo.com   \n",
       "2   http                  www.nytimes.com   \n",
       "3   http                    evonomics.com   \n",
       "4  HTTPS                       github.com   \n",
       "\n",
       "                                                   2  \n",
       "0  Technology-Ventures-Enterprise-Thomas-Byers/dp...  \n",
       "1                                                     \n",
       "2                2007/11/07/movies/07stein.html?_r=0  \n",
       "3  advertising-cannot-maintain-internet-heres-sol...  \n",
       "4                                        keppel/pinn  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_url_parts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url_parts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-169440fa283b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0murl_parts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'url_parts' is not defined"
     ]
    }
   ],
   "source": [
    "url_parts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Named Capture Groups to Extract Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final task will be to name these columns, which we'll do using named capture groups. Let's look at the example from the previous screen where we used two capture groups to extract the date and time as two separate columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0      1\n",
      "0    8/4/2016  11:52\n",
      "1   6/23/2016  22:20\n",
      "2   6/17/2016   0:01\n",
      "3   9/30/2015   4:12\n",
      "4  10/31/2015   9:48\n"
     ]
    }
   ],
   "source": [
    "created_at = hn['created_at'].head()\n",
    "\n",
    "pattern = r\"(.+) (.+)\"\n",
    "dates_times = created_at.str.extract(pattern)\n",
    "print(dates_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to name a capture group we use the syntax ?P, where name is the name of our capture group. This syntax goes after the open parentheses, but before the regex syntax that defines the capture group: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   time\n",
      "0    8/4/2016  11:52\n",
      "1   6/23/2016  22:20\n",
      "2   6/17/2016   0:01\n",
      "3   9/30/2015   4:12\n",
      "4  10/31/2015   9:48\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"(?P<date>.+) (?P<time>.+)\"\n",
    "dates_times = created_at.str.extract(pattern)\n",
    "print(dates_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add name to our capture group from the previous screen to create a dataframe with named columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  protocol                           domain  \\\n",
      "0     http  www.interactivedynamicvideo.com   \n",
      "1     http                  www.thewire.com   \n",
      "2    https                   www.amazon.com   \n",
      "3     http                  www.nytimes.com   \n",
      "4     http                  arstechnica.com   \n",
      "\n",
      "                                                path  \n",
      "0                                                     \n",
      "1  entertainment/2013/04/florida-djs-april-fools-...  \n",
      "2  Technology-Ventures-Enterprise-Thomas-Byers/dp...  \n",
      "3                2007/11/07/movies/07stein.html?_r=0  \n",
      "4  business/2015/10/comcast-and-other-isps-boost-...  \n"
     ]
    }
   ],
   "source": [
    "# pattern = r\"(https?)://([\\w\\.\\-]+)/?(.*)\"\n",
    "pattern = r\"(?P<protocol>https?)://(?P<domain>[\\w\\.\\-]+)/?(?P<path>.*)\"\n",
    "url_parts = hn['url'].str.extract(pattern, flags=re.I)\n",
    "print(url_parts.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
